{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from BuildingBlocks import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crops current context if it exceeds the supported context size, e.g., if LLM supports only 5 tokens, and the context size is 10, then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        # Focuses only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        # (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim = -1)\n",
    "        # greedy\n",
    "        idx_next = torch.argmax(probas, dim = -1, keepdim = True)\n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# example inputs/targets accepted by gpt model\n",
    "# [\"every effort moves\", \"I really like\"]\n",
    "inputs = torch.tensor([[16833, 3626, 6100], \n",
    "                        [40, 1107, 588]]) \n",
    "# [\"effort moves you\", \"really lilke chocolate\"]\n",
    "targets = torch.tensor([[3626, 6100, 345],\n",
    "                        [1107, 588, 11311]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim = -1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 两个相邻的`f-string`（如 `f\"...\"f\"...\"`）可以连在一起使用，这是由Python的 ​​隐式字符串字面值拼接​​ 特性实现的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[ 832],\n",
      "         [ 340],\n",
      "         [ 262]],\n",
      "\n",
      "        [[ 367],\n",
      "         [1239],\n",
      "         [ 757]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  through it the\n"
     ]
    }
   ],
   "source": [
    "# covnertion: probas -> token_ids -> text\n",
    "token_ids = torch.argmax(probas, dim = -1, keepdim = True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***The goal of model training is to ensure that the probability values corresponding to the highlighted target token IDs are maximized***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4557e-06, 4.3212e-06, 2.5012e-03])\n",
      "Text 2: tensor([1.0862e-04, 1.7851e-04, 5.9863e-07])\n"
     ]
    }
   ],
   "source": [
    "# print the initial softmax probability scores \n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.8065, -12.3520,  -5.9910,  -9.1277,  -8.6309, -14.3286])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.3728)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.3728)\n"
     ]
    }
   ],
   "source": [
    "# cross entropy = negative average log probability\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# .flatten(0, 1): flatten 0-th and 1-th dim to 1 dim\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean', label_smoothing=0.0)`\n",
    "\n",
    "- `input` (Tensor) - shape: `(N, C)`, `N` for batch size, `C` for number of classes – ***Predicted unnormalized logits***; see Shape section below for supported shapes.\n",
    "\n",
    "- `target` (Tensor) - shape: `()`/`(N)` – Ground truth ***class indices*** or class probabilities; If containing class probabilities, same shape as the input and each value should be between `[0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.3728)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding = \"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio*len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BuildingBlocks import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# check dataloader output\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    # eval\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calc_loss_loader` function iterates over all batches in a given data loader, accumulates the loss in the total_loss variable, and then computes and averages the loss over the total number of batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # in case if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches = eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches = eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model, idx = encoded,\n",
    "            max_new_tokens = 50, context_size = context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # reset grads\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # print train details info\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0004, weight_decay= 0.1\n",
    ")\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs = num_epochs, eval_freq = 5, eval_iter = 5, start_context = \"Every effort moves you\", tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate text:\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# temperature scaling\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "\n",
    "}\n",
    "\n",
    "inverse_vocab = {v:k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim = 0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples = 1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "    for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temperature\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim =0)\n",
    "\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize = (5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i*bar_width, scaled_probas[i], bar_width, label = f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation = 90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    # 比第3大的值小的所有值设定为-inf\n",
    "    condition = next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float('-inf')),\n",
    "    other = next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim = 0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature = 0.0, top_k = None, eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            # the k-th largest val\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        if temperature > 0.0:\n",
    "            # makes the distribution \"flatter\"\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# 622 model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model together with optimizer\n",
    "# 1.81 GB\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# restart kernel (reset all var) before running this cell\n",
    "# =========================================\n",
    "# load model and optimizer (checkpoint)\n",
    "import torch\n",
    "from BuildingBlocks import GPTModel\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location = device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-4, weight_decay= 0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.409, Val loss 6.511\n",
      "Ep 1 (Step 000005): Train loss 0.286, Val loss 6.471\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, when I back the window-curtains, moved aside a _jardiniere_ full of\n",
      "Ep 2 (Step 000010): Train loss 0.227, Val loss 6.598\n",
      "Ep 2 (Step 000015): Train loss 0.193, Val loss 6.647\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.4090253531932831,\n",
       "  0.2857893079519272,\n",
       "  0.22701289653778076,\n",
       "  0.1930058091878891],\n",
       " [6.51075553894043, 6.471151828765869, 6.598359107971191, 6.646981239318848],\n",
       " [512, 3072, 5632, 8192])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue to train for 2 more epoch\n",
    "train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs = 2, eval_freq = 5, eval_iter = 5, start_context = \"Every effort moves you\", tokenizer = tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-HW-Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
